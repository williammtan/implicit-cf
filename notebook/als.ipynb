{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('anaconda3': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "e134e05457d34029b6460cd73bbf1ed73f339b5b6d98c95be70b69eba114fe95"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import findspark\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 2.4088502e-02,  4.5487039e-02, -5.9732427e-03, ...,\n",
       "         3.9603140e-02, -1.2920763e-01,  3.1931356e-02],\n",
       "       [ 5.6173459e-02, -3.1872738e-02, -1.8654661e-02, ...,\n",
       "         4.1457918e-02,  7.9145906e-03, -8.8962384e-02],\n",
       "       [ 3.6168084e-02,  5.5262349e-03,  2.6637517e-02, ...,\n",
       "         7.8163475e-02, -1.2771778e-01,  7.8532314e-03],\n",
       "       ...,\n",
       "       [ 3.4128662e-02, -1.2621130e-02,  1.8723119e-02, ...,\n",
       "         6.5758708e-03, -1.1179015e-02, -1.4638690e-02],\n",
       "       [ 2.6132176e-03,  2.0419287e-03,  2.0713739e-03, ...,\n",
       "        -4.4840756e-03, -3.8591241e-03, -8.2134764e-05],\n",
       "       [ 3.5262550e-03, -4.0169805e-03,  4.5639514e-03, ...,\n",
       "        -6.4203939e-03, -1.6353601e-03, -2.8254604e-03]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "col = np.load(os.path.join(os.path.join(os.getcwd(), '../models/als_ml_train_20210310_084446/col.npy')))\n",
    "col"
   ]
  },
  {
   "source": [
    "# Pre-processing Data\n",
    "- Import from csv and convert to df\n",
    "- Drop unused columns and filter invalid rows\n",
    "- Make interaction array\n",
    "- Split data to train and test sets\n",
    "- Convert training set to sparse matrix R"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   user_id            username  item_id                product_name  \\\n",
       "0        6  Andy Fajar Handika     9463         Nasi Goreng Selimut   \n",
       "1        6  Andy Fajar Handika     3663   Nasi Jenggo Ikan Cakalang   \n",
       "2        6  Andy Fajar Handika     5930            Nasi Kebuli Sapi   \n",
       "3       12         Thomas Dian     6845  Nasi Rames Ayam Bumbu Bali   \n",
       "4       12         Thomas Dian     7233        Nasi Dori Asam Manis   \n",
       "\n",
       "            status  \n",
       "0     VOID BY USER  \n",
       "1     VOID BY USER  \n",
       "2     VOID BY USER  \n",
       "3          SUCCESS  \n",
       "4  PAYMENT EXPIRED  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>username</th>\n      <th>item_id</th>\n      <th>product_name</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>Andy Fajar Handika</td>\n      <td>9463</td>\n      <td>Nasi Goreng Selimut</td>\n      <td>VOID BY USER</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>Andy Fajar Handika</td>\n      <td>3663</td>\n      <td>Nasi Jenggo Ikan Cakalang</td>\n      <td>VOID BY USER</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>Andy Fajar Handika</td>\n      <td>5930</td>\n      <td>Nasi Kebuli Sapi</td>\n      <td>VOID BY USER</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12</td>\n      <td>Thomas Dian</td>\n      <td>6845</td>\n      <td>Nasi Rames Ayam Bumbu Bali</td>\n      <td>SUCCESS</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12</td>\n      <td>Thomas Dian</td>\n      <td>7233</td>\n      <td>Nasi Dori Asam Manis</td>\n      <td>PAYMENT EXPIRED</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# import data and convert to df\n",
    "path = os.path.join(os.getcwd(), '../data/u.purchase.csv')\n",
    "\n",
    "names = ['user_id','username','item_id','product_name','status']\n",
    "df = pd.read_csv(path, ',', names=names, engine='python', skiprows=1) # skip header row\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    user_id  item_id\n",
       "3        12     6845\n",
       "9        12     6271\n",
       "12       76     7120\n",
       "13       76     7121\n",
       "14       76     7122"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>12</td>\n      <td>6845</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>12</td>\n      <td>6271</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>76</td>\n      <td>7120</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>76</td>\n      <td>7121</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>76</td>\n      <td>7122</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# remove unused columns\n",
    "df.drop(['username', 'product_name'], axis=1, inplace=True)\n",
    "\n",
    "# only keep SUCCESS status\n",
    "df = df.drop(df[df.status!='SUCCESS'].index)\n",
    "df.drop(['status'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique users and items\n",
    "users = df.user_id.unique()\n",
    "items = df.item_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[   0,    0,    0],\n",
       "       [   0,    1,    1],\n",
       "       [   0,    0,    1],\n",
       "       ...,\n",
       "       [9383,  105,    1],\n",
       "       [9384,  585,    1],\n",
       "       [9385,  125,    1]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Make interaction list [u, i, r_ui]\n",
    "interactions = np.array([[0,0,0]])\n",
    "\n",
    "for u in users:\n",
    "    user_purchases = df[df.user_id==u].item_id\n",
    "    unique, counts = np.unique(user_purchases, return_counts=True)\n",
    "    u_interactions = np.array(list(zip(np.zeros(len(counts), dtype=int), unique, counts)))\n",
    "    for index, u_in in enumerate(u_interactions):\n",
    "        # change item to indexes and add user index\n",
    "        _, i, r_ui = u_in\n",
    "        i_i = np.where(items==i)[0]\n",
    "        u_i = np.where(users==u)[0]\n",
    "        u_interactions[index] = [u_i, i_i, r_ui]\n",
    "    # add to interactions array\n",
    "    interactions = np.vstack([interactions, u_interactions]) \n",
    "\n",
    "np.delete(interactions, 0)\n",
    "interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training\n",
    "np.random.seed(0)\n",
    "\n",
    "def train_test_split(interactions, ts_ratio):\n",
    "    shuffled = np.random.permutation(interactions)\n",
    "    ts_length = round(ts_ratio * len(interactions))\n",
    "    ts_interactions = shuffled[:ts_length]\n",
    "    tr_interactions = shuffled[ts_length:]\n",
    "    return tr_interactions, ts_interactions\n",
    "\n",
    "tr_interactions, ts_interactions = train_test_split(interactions, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Make R (r_ui matrix)\n",
    "from scipy import sparse\n",
    "u_tr, i_tr, r_tr = zip(*tr_interactions)\n",
    "R = sparse.csr_matrix((r_tr, (u_tr, i_tr)), shape=(len(users), len(items)))\n",
    "R.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Make ts (r_ui matrix)\n",
    "\n",
    "u_ts, i_ts, r_ts = zip(*ts_interactions)\n",
    "ts = sparse.csr_matrix((r_ts, (u_ts, i_ts)), shape=(len(users), len(items)))\n",
    "ts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.259190269509105"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "sparcity = R.count_nonzero() / (len(users)*len(items))\n",
    "sparcity*100"
   ]
  },
  {
   "source": [
    "# Create Model\n",
    "- Init weights (confidence matrix)\n",
    "- train()\n",
    "    1. Load params (stored in /data/x.json)\n",
    "    2. Iterate num of iterations\n",
    "    3. Alternate solving row and columns\n",
    "    4. Return row and column matrices\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "def implicit_als(R, _alpha=40, iters=10, _lambda=0.1, latent_factors=10):\n",
    "    C = R * _alpha\n",
    "    n_users, n_items = R.shape\n",
    "\n",
    "    # init random X and Y matrices with normal distribution\n",
    "    X = sparse.csr_matrix(np.random.normal(size=(n_users, latent_factors)))\n",
    "    Y = sparse.csr_matrix(np.random.normal(size=(n_items, latent_factors)))\n",
    "\n",
    "    # compute I, and lambda * I\n",
    "    I = sparse.eye(latent_factors)\n",
    "\n",
    "    X_I = sparse.eye(n_users)\n",
    "    Y_I = sparse.eye(n_items)\n",
    "    l_I = _lambda * I\n",
    "\n",
    "    # TRAIN ITERATIONS\n",
    "    for i in range(iters):\n",
    "        print(f\"iteration {i+1} of {iters}\")\n",
    "\n",
    "        yTy = Y.T.dot(Y)\n",
    "        xTx = X.T.dot(X)\n",
    "\n",
    "        # loop all users\n",
    "        for u in range(n_users):\n",
    "            u_row = C[u,:].toarray()[0]\n",
    "\n",
    "            # calculate preference p(u) binary values\n",
    "            p_u = u_row.copy()\n",
    "            p_u[p_u != 0] = 1.0\n",
    "\n",
    "            # calculate Cu and CuI\n",
    "            CuI = sparse.diags(u_row)\n",
    "            Cu = CuI + Y_I\n",
    "\n",
    "            yT_CuI_y = Y.T.dot(CuI).dot(Y)\n",
    "            yT_Cu_pu = Y.T.dot(Cu).dot(p_u.T)\n",
    "            X[u] = spsolve(yTy + yT_CuI_y + l_I, yT_Cu_pu) # change user row to optimised\n",
    "        \n",
    "        for i in range(n_items):\n",
    "            i_row = C[:,i].T.toarray()[0]\n",
    "\n",
    "            p_i = i_row.copy()\n",
    "            p_i[p_i != 0] = 1.0\n",
    "\n",
    "            CiI = sparse.diags(i_row)\n",
    "            Ci = CiI + X_I\n",
    "\n",
    "            xT_Ci_x = X.T.dot(CiI).dot(X)\n",
    "            xT_Ci_pi = X.T.dot(Ci).dot(p_i.T)\n",
    "            Y[i] = spsolve(xTx + xT_Ci_x + l_I, xT_Ci_pi)\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = implicit_als(R, _alpha=15, iters=10, _lambda=0.1, latent_factors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.92it/s]\n"
     ]
    }
   ],
   "source": [
    "import implicit\n",
    "\n",
    "model = implicit.als.AlternatingLeastSquares(factors=20, regularization=0.2, iterations=10)\n",
    "\n",
    "# Calculate the confidence by multiplying it by our alpha value.\n",
    "alpha_val = 20\n",
    "data_conf = (R.T * alpha_val).astype('double')\n",
    "\n",
    "model.fit(data_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def rmse(pred, ts):\n",
    "    ts = ts.toarray()\n",
    "    mse = 0\n",
    "    for u in range(ts.shape[0]):\n",
    "        error = ts[u] - pred[u]\n",
    "        mse += np.sum(error**2)\n",
    "        mse /= ts.shape[1]\n",
    "    mse /= ts.shape[0]\n",
    "    rmse = math.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "source": [
    "u_ts, i_ts, r_ts = zip(*ts_interactions)\n",
    "ts = sparse.csr_matrix((r_ts, (u_ts, i_ts)), shape=(len(users), len(items)))\n",
    "len(r_tr)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'norm_pred' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3afdf47653d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'norm_pred' is not defined"
     ]
    }
   ],
   "source": [
    "rmse(norm_pred, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "pred = np.dot(model.user_factors, model.item_factors.T)\n",
    "norm_pred = normalize(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(9386, 5522)"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "source": [
    "norm_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "names = ['user_id','username','item_id','product_name','status']\n",
    "df_new = pd.read_csv(path, ',', names=names, engine='python', skiprows=1) # skip header row\n",
    "df_new.drop(['user_id', 'username', 'status'], axis=1, inplace=True)\n",
    "df_new = df_new.drop_duplicates()\n",
    "item_names = df_new.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "np.where(item_names[:,0]==14936)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/default.json'"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "os.path.join(\"/hyperparams\", \"/default.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_id, k):\n",
    "    user_i = np.where(users==user_id)[0]\n",
    "    user_pred = norm_pred[user_i][0]\n",
    "    recommendations = []\n",
    "    for _ in range(k):\n",
    "        max_i = np.argmax(user_pred)\n",
    "        user_pred = np.delete(user_pred, max_i)\n",
    "        item_id = items[max_i]\n",
    "        item_name = item_names[np.where(item_names[:,0]==item_id)[0][0]][1]\n",
    "        recommendations.append(item_name)\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-73bb61667a21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m144\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-ba662c5cf3e7>\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(user_id, k)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0muser_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0muser_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrecommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "recommend(144, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "normed_matrix = normalize(matrix, axis=1, norm='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 68072 is out of bounds for axis 0 with size 9386",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-e1c39c461a5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecommended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m68072\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mimplicit/recommender_base.pyx\u001b[0m in \u001b[0;36mimplicit.recommender_base.MatrixFactorizationBase.recommend\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mimplicit/recommender_base.pyx\u001b[0m in \u001b[0;36mimplicit.recommender_base.MatrixFactorizationBase._user_factor\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 68072 is out of bounds for axis 0 with size 9386"
     ]
    }
   ],
   "source": [
    "recommended = model.recommend(68072, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'SparkContext' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-127c4e87bd0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommendation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mALS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"local\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"First App\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'SparkContext' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark import SparkContent\n",
    "sc = SparkContext(\"local\", \"First App\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(tr_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Ratings should be represented by either an RDD or a DataFrame, but got <class 'pandas.core.frame.DataFrame'>.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d8a811d400b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mALS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainImplicit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pyspark/mllib/recommendation.py\u001b[0m in \u001b[0;36mtrainImplicit\u001b[0;34m(cls, ratings, rank, iterations, lambda_, blocks, alpha, nonnegative, seed)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[0;32m--> 324\u001b[0;31m         model = callMLlibFunc(\"trainImplicitALSModel\", cls._prepare(ratings), rank,\n\u001b[0m\u001b[1;32m    325\u001b[0m                               iterations, lambda_, blocks, alpha, nonnegative, seed)\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mMatrixFactorizationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pyspark/mllib/recommendation.py\u001b[0m in \u001b[0;36m_prepare\u001b[0;34m(cls, ratings)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             raise TypeError(\"Ratings should be represented by either an RDD or a DataFrame, \"\n\u001b[0m\u001b[1;32m    233\u001b[0m                             \"but got %s.\" % type(ratings))\n\u001b[1;32m    234\u001b[0m         \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Ratings should be represented by either an RDD or a DataFrame, but got <class 'pandas.core.frame.DataFrame'>."
     ]
    }
   ],
   "source": [
    "model = ALS.trainImplicit(tr_df, rank=5, lambda_=0.01, alpha=1.0, iterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}