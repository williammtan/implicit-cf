{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "configured-modification",
   "metadata": {},
   "source": [
    "# Memory Based Collaborative Filtering\n",
    "\n",
    "Create and train memory based CF model\n",
    "\n",
    "Steps:\n",
    "1. Find user/item similarities based on ratings\n",
    "2. Calculate ratings based on user/item similarity and fill matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "single-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import matplotlib as plt\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "emerging-classics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/williamtan/Code/recommender_system/notebook/../data/u.data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>select_item</td>\n",
       "      <td>00C40CEE3AB94849BA5CC14F8CF91A9C</td>\n",
       "      <td>792</td>\n",
       "      <td>Putri Dimsum Bojonggede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>select_item</td>\n",
       "      <td>0375AD60BF4748A98D396030F00494AE</td>\n",
       "      <td>662</td>\n",
       "      <td>Blaztfood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>select_item</td>\n",
       "      <td>03FC0F5053C74111A26E4F9EA60CA3D6</td>\n",
       "      <td>49</td>\n",
       "      <td>Mie Ayam Ditdot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>select_item</td>\n",
       "      <td>03FC0F5053C74111A26E4F9EA60CA3D6</td>\n",
       "      <td>829</td>\n",
       "      <td>DAPUR ABADI MEREKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>add_to_cart</td>\n",
       "      <td>03FC0F5053C74111A26E4F9EA60CA3D6</td>\n",
       "      <td>7080</td>\n",
       "      <td>Paket ayam bakar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    event_name                           user_id  item_id  \\\n",
       "0  select_item  00C40CEE3AB94849BA5CC14F8CF91A9C      792   \n",
       "1  select_item  0375AD60BF4748A98D396030F00494AE      662   \n",
       "2  select_item  03FC0F5053C74111A26E4F9EA60CA3D6       49   \n",
       "3  select_item  03FC0F5053C74111A26E4F9EA60CA3D6      829   \n",
       "4  add_to_cart  03FC0F5053C74111A26E4F9EA60CA3D6     7080   \n",
       "\n",
       "                 item_name  \n",
       "0  Putri Dimsum Bojonggede  \n",
       "1                Blaztfood  \n",
       "2         Mie Ayam Ditdot   \n",
       "3       DAPUR ABADI MEREKA  \n",
       "4        Paket ayam bakar   "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "path = os.path.join(os.getcwd(), '../data/u.data.csv')\n",
    "print(path)\n",
    "\n",
    "names = ['event_name', 'user_id', 'item_id', 'item_name']\n",
    "df = pd.read_csv(path, ',', names=names, engine='python', skiprows=1) # skip header row\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sonic-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create matrix from df\n",
    "users = df.user_id.unique()\n",
    "items = df.item_id.unique()\n",
    "n_users = len(users)\n",
    "n_items = len(items)\n",
    "\n",
    "# create dict from user_index to user_id and item_index to item_id\n",
    "\n",
    "user_id_i = {}\n",
    "item_id_i = {}\n",
    "for u in range(n_users):\n",
    "    user_id_i[users[u]] = u\n",
    "for i in range(n_items):\n",
    "    item_id_i[items[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "extended-senegal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>select_item</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Putri Dimsum Bojonggede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>select_item</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Blaztfood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>select_item</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Mie Ayam Ditdot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>select_item</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>DAPUR ABADI MEREKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>add_to_cart</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Paket ayam bakar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>begin_checkout</td>\n",
       "      <td>517</td>\n",
       "      <td>993</td>\n",
       "      <td>Tongkol Suwir Cabe Ijo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>begin_checkout</td>\n",
       "      <td>517</td>\n",
       "      <td>2188</td>\n",
       "      <td>Vietnamese Spring Roll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>begin_checkout</td>\n",
       "      <td>891</td>\n",
       "      <td>320</td>\n",
       "      <td>Fish and Chips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>begin_checkout</td>\n",
       "      <td>891</td>\n",
       "      <td>296</td>\n",
       "      <td>Fit Burger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>begin_checkout</td>\n",
       "      <td>362</td>\n",
       "      <td>3054</td>\n",
       "      <td>CHEESY BEEF KEBAB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           event_name  user_id  item_id                item_name\n",
       "0         select_item        0        0  Putri Dimsum Bojonggede\n",
       "1         select_item        1        1                Blaztfood\n",
       "2         select_item        2        2         Mie Ayam Ditdot \n",
       "3         select_item        2        3       DAPUR ABADI MEREKA\n",
       "4         add_to_cart        2        4        Paket ayam bakar \n",
       "...               ...      ...      ...                      ...\n",
       "15995  begin_checkout      517      993   Tongkol Suwir Cabe Ijo\n",
       "15996  begin_checkout      517     2188   Vietnamese Spring Roll\n",
       "15997  begin_checkout      891      320           Fish and Chips\n",
       "15998  begin_checkout      891      296               Fit Burger\n",
       "15999  begin_checkout      362     3054        CHEESY BEEF KEBAB\n",
       "\n",
       "[16000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert df user and item id column to indexes\n",
    "df[\"user_id\"].replace(user_id_i, inplace=True)\n",
    "df[\"item_id\"].replace(item_id_i, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "large-marriage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0., 15.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0., 15., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_weights = {'add_to_cart': 2, 'view_item': 1, 'add_to_wishlist': 1.5, 'select_promotion': 1, 'view_item_list': 1, 'select_item': 1, 'begin_checkout': 3, 'remove_from_cart': -1}    \n",
    "alpha = 15\n",
    "\n",
    "conf = np.zeros((n_users, n_items)) # init confidence matrix\n",
    "for row in df.itertuples():\n",
    "    # change conf by alpha*weight\n",
    "    for event, weight in event_weights.items():\n",
    "        if event == row.event_name:\n",
    "            conf[row.user_id, row.item_id] += alpha*weight\n",
    "\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "royal-module",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7934\n",
      "1984\n",
      "[[ 792  128]\n",
      " [ 580    6]\n",
      " [ 250 1577]\n",
      " ...\n",
      " [ 219  926]\n",
      " [ 915 3098]\n",
      " [ 181   11]]\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "np.random.seed(0)\n",
    "\n",
    "def train_test_split(conf):\n",
    "    sparse_ratings = np.zeros(conf.shape) # init sparse matrix\n",
    "\n",
    "    users_i, items_i = np.nonzero(conf)\n",
    "    indexes = np.array((users_i, items_i)).T\n",
    "    np.random.shuffle(indexes)\n",
    "    \n",
    "    # fill in matrix\n",
    "    train_indexes = indexes[0:int(len(indexes)*0.8)]\n",
    "    test_indexes = indexes[int(len(indexes)*0.8):]\n",
    "    \n",
    "    train_set = sparse_ratings.copy()\n",
    "    test_set = sparse_ratings.copy()\n",
    "\n",
    "    for i in train_indexes:\n",
    "        train_set[i[0], i[1]] = conf[i[0], i[1]]\n",
    "    \n",
    "    for i in test_indexes:\n",
    "        test_set[i[0], i[1]] = conf[i[0], i[1]]\n",
    "\n",
    "    return sparse.csr_matrix(train_set), sparse.csr_matrix(test_set), test_indexes\n",
    "    \n",
    "\n",
    "train_set, test_set, test_indexes = train_test_split(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "relative-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange, tqdm\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "def implicit_weighted_ALS(training_set, lambda_val = 0.1, alpha = 40, iterations = 10, rank_size = 20, seed = 0):\n",
    "    '''\n",
    "    Implicit weighted ALS taken from Hu, Koren, and Volinsky 2008. Designed for alternating least squares and implicit\n",
    "    feedback based collaborative filtering. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    training_set - Our matrix of ratings with shape m x n, where m is the number of users and n is the number of items.\n",
    "    Should be a sparse csr matrix to save space. \n",
    "    \n",
    "    lambda_val - Used for regularization during alternating least squares. Increasing this value may increase bias\n",
    "    but decrease variance. Default is 0.1. \n",
    "    \n",
    "    alpha - The parameter associated with the confidence matrix discussed in the paper, where Cui = 1 + alpha*Rui. \n",
    "    The paper found a default of 40 most effective. Decreasing this will decrease the variability in confidence between\n",
    "    various ratings.\n",
    "    \n",
    "    iterations - The number of times to alternate between both user feature vector and item feature vector in\n",
    "    alternating least squares. More iterations will allow better convergence at the cost of increased computation. \n",
    "    The authors found 10 iterations was sufficient, but more may be required to converge. \n",
    "    \n",
    "    rank_size - The number of latent features in the user/item feature vectors. The paper recommends varying this \n",
    "    between 20-200. Increasing the number of features may overfit but could reduce bias. \n",
    "    \n",
    "    seed - Set the seed for reproducible results\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The feature vectors for users and items. The dot product of these feature vectors should give you the expected \n",
    "    \"rating\" at each point in your original matrix. \n",
    "    '''\n",
    "    \n",
    "    # first set up our confidence matrix\n",
    "    \n",
    "    conf = (alpha*training_set) # To allow the matrix to stay sparse, I will add one later when each row is taken \n",
    "                                # and converted to dense. \n",
    "    num_user = conf.shape[0]\n",
    "    num_item = conf.shape[1] # Get the size of our original ratings matrix, m x n\n",
    "    \n",
    "    # initialize our X/Y feature vectors randomly with a set seed\n",
    "    rstate = np.random.RandomState(seed)\n",
    "    \n",
    "    X = sparse.csr_matrix(rstate.normal(size = (num_user, rank_size))) # Random numbers in a m x rank shape\n",
    "    Y = sparse.csr_matrix(rstate.normal(size = (num_item, rank_size))) # Normally this would be rank x n but we can \n",
    "                                                                 # transpose at the end. Makes calculation more simple.\n",
    "    X_eye = sparse.eye(num_user)\n",
    "    Y_eye = sparse.eye(num_item)\n",
    "    lambda_eye = lambda_val * sparse.eye(rank_size) # Our regularization term lambda*I. \n",
    "    \n",
    "    # We can compute this before iteration starts. \n",
    "    \n",
    "    # Begin iterations\n",
    "    for iter_step in trange(iterations): # Iterate back and forth between solving X given fixed Y and vice versa\n",
    "        # Compute yTy and xTx at beginning of each iteration to save computing time\n",
    "        yTy = Y.T.dot(Y)\n",
    "        xTx = X.T.dot(X)\n",
    "        # Being iteration to solve for X based on fixed Y\n",
    "        for u in range(num_user):\n",
    "            conf_samp = conf[u,:].toarray() # Grab user row from confidence matrix and convert to dense\n",
    "            pref = conf_samp.copy() \n",
    "            pref[pref != 0] = 1 # Create binarized preference vector \n",
    "            CuI = sparse.diags(conf_samp, [0]) # Get Cu - I term, don't need to subtract 1 since we never added it \n",
    "            yTCuIY = Y.T.dot(CuI).dot(Y) # This is the yT(Cu-I)Y term \n",
    "            yTCupu = Y.T.dot(CuI + Y_eye).dot(pref.T) # This is the yTCuPu term, where we add the eye back in\n",
    "                                                      # Cu - I + I = Cu\n",
    "            X[u] = spsolve(yTy + yTCuIY + lambda_eye, yTCupu) \n",
    "            # Solve for Xu = ((yTy + yT(Cu-I)Y + lambda*I)^-1)yTCuPu, equation 4 from the paper  \n",
    "        # Begin iteration to solve for Y based on fixed X \n",
    "        for i in range(num_item):\n",
    "            conf_samp = conf[:,i].T.toarray() # transpose to get it in row format and convert to dense\n",
    "            pref = conf_samp.copy()\n",
    "            pref[pref != 0] = 1 # Create binarized preference vector\n",
    "            CiI = sparse.diags(conf_samp, [0]) # Get Ci - I term, don't need to subtract 1 since we never added it\n",
    "            xTCiIX = X.T.dot(CiI).dot(X) # This is the xT(Cu-I)X term\n",
    "            xTCiPi = X.T.dot(CiI + X_eye).dot(pref.T) # This is the xTCiPi term\n",
    "            Y[i] = spsolve(xTx + xTCiIX + lambda_eye, xTCiPi)\n",
    "            # Solve for Yi = ((xTx + xT(Cu-I)X) + lambda*I)^-1)xTCiPi, equation 5 from the paper\n",
    "    # End iterations\n",
    "    return X, Y.T # Transpose at the end to make up for not being transposed at the beginning. \n",
    "                         # Y needs to be rank x n. Keep these as separate matrices for scale reasons. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "single-piano",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:30<00:00, 15.01s/it]\n"
     ]
    }
   ],
   "source": [
    "X, Y = implicit_weighted_ALS(train_set, lambda_val = 0.1, alpha = 15, iterations = 10, rank_size = 10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "another-carry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (1, 3131)\t-0.10990481172516653\n",
      "  (1, 3130)\t-0.10990481172516653\n",
      "  (1, 3129)\t0.003778713863801679\n",
      "  (1, 3126)\t0.0004175395967061374\n",
      "  (1, 3125)\t0.005542608910799197\n",
      "  (1, 3124)\t0.005542608910799197\n",
      "  (1, 3123)\t-0.391658622985251\n",
      "  (1, 3122)\t-0.4273782177906801\n",
      "  (1, 3121)\t-0.391658622985251\n",
      "  (1, 3120)\t-0.391658622985251\n",
      "  (1, 3119)\t-0.391658622985251\n",
      "  (1, 3118)\t-0.391658622985251\n",
      "  (1, 3117)\t-0.4273782177906801\n",
      "  (1, 3115)\t-0.4273782177906801\n",
      "  (1, 3114)\t-0.391658622985251\n",
      "  (1, 3113)\t-0.391658622985251\n",
      "  (1, 3112)\t-0.391658622985251\n",
      "  (1, 3111)\t-0.391658622985251\n",
      "  (1, 3110)\t0.008912470836042144\n",
      "  (1, 3109)\t0.011506400010700656\n",
      "  (1, 3107)\t-0.210970065348684\n",
      "  (1, 3105)\t0.014538312793588873\n",
      "  (1, 3103)\t0.009472620522539825\n",
      "  (1, 3102)\t0.009455908819678237\n",
      "  (1, 3101)\t0.009472620522539825\n",
      "  :\t:\n",
      "  (926, 25)\t-0.05172244221631715\n",
      "  (926, 24)\t-0.006278871100173153\n",
      "  (926, 23)\t-0.12099824868552413\n",
      "  (926, 22)\t-0.0021126601870202974\n",
      "  (926, 21)\t-0.393214500822647\n",
      "  (926, 20)\t-0.06786926713325737\n",
      "  (926, 19)\t-0.004310887743559061\n",
      "  (926, 18)\t0.0783968468423273\n",
      "  (926, 17)\t-0.006641724222660461\n",
      "  (926, 16)\t0.37221391159592315\n",
      "  (926, 15)\t-0.3170536983249499\n",
      "  (926, 14)\t-0.026475109954657766\n",
      "  (926, 13)\t0.0598239650144102\n",
      "  (926, 12)\t-0.01946981350317395\n",
      "  (926, 11)\t0.06016006185791978\n",
      "  (926, 10)\t-0.014278856744972729\n",
      "  (926, 9)\t0.08103287224054181\n",
      "  (926, 8)\t-0.03117554762787625\n",
      "  (926, 7)\t0.0008555769410780734\n",
      "  (926, 6)\t-0.012979949404490376\n",
      "  (926, 5)\t0.2880656551202806\n",
      "  (926, 4)\t0.13298934610126342\n",
      "  (926, 3)\t0.023789146535281136\n",
      "  (926, 2)\t0.11368732621019556\n",
      "  (926, 1)\t-0.4034612563040336\n"
     ]
    }
   ],
   "source": [
    "prediction = X.dot(Y)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "opposed-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def rmse(prediction, test_indexes):\n",
    "    value = 0\n",
    "    for i in test_indexes:\n",
    "        value += math.sqrt((prediction[i[0], i[1]]-conf[i[0], i[1]])**2)\n",
    "    return value / len(test_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "neural-immigration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.4326200972188"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_value = rmse(prediction, test_indexes)\n",
    "rmse_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bacterial-april",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1984\n"
     ]
    }
   ],
   "source": [
    "print(len(np.nonzero(test_set.toarray())[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "nutritional-advisory",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7968b258f09f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muser_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrecommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mimplicit/recommender_base.pyx\u001b[0m in \u001b[0;36mimplicit.recommender_base.MatrixFactorizationBase.recommend\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mimplicit/recommender_base.pyx\u001b[0m in \u001b[0;36mimplicit.recommender_base.MatrixFactorizationBase._user_factor\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "user_items = conf\n",
    "recommendations = model.recommend(train_set, user_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-musical",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
