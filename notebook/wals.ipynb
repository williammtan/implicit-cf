{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('anaconda3': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "e134e05457d34029b6460cd73bbf1ed73f339b5b6d98c95be70b69eba114fe95"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# WALS Matrix Factorization\n",
    "\n",
    "Steps:\n",
    "<ol>\n",
    "<li>Preprocess data</li>\n",
    "<li>Build model</li>\n",
    "<li>Train model</li>\n",
    "<li>Hyperparameter tuning</li>\n",
    "<li>Validate model</li>\n",
    "</ol>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   user_id            username  item_id                product_name  \\\n",
       "0        6  Andy Fajar Handika     9463         Nasi Goreng Selimut   \n",
       "1        6  Andy Fajar Handika     3663   Nasi Jenggo Ikan Cakalang   \n",
       "2        6  Andy Fajar Handika     5930            Nasi Kebuli Sapi   \n",
       "3       12         Thomas Dian     6845  Nasi Rames Ayam Bumbu Bali   \n",
       "4       12         Thomas Dian     7233        Nasi Dori Asam Manis   \n",
       "\n",
       "            status  \n",
       "0     VOID BY USER  \n",
       "1     VOID BY USER  \n",
       "2     VOID BY USER  \n",
       "3          SUCCESS  \n",
       "4  PAYMENT EXPIRED  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>username</th>\n      <th>item_id</th>\n      <th>product_name</th>\n      <th>status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>Andy Fajar Handika</td>\n      <td>9463</td>\n      <td>Nasi Goreng Selimut</td>\n      <td>VOID BY USER</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>Andy Fajar Handika</td>\n      <td>3663</td>\n      <td>Nasi Jenggo Ikan Cakalang</td>\n      <td>VOID BY USER</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>Andy Fajar Handika</td>\n      <td>5930</td>\n      <td>Nasi Kebuli Sapi</td>\n      <td>VOID BY USER</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12</td>\n      <td>Thomas Dian</td>\n      <td>6845</td>\n      <td>Nasi Rames Ayam Bumbu Bali</td>\n      <td>SUCCESS</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12</td>\n      <td>Thomas Dian</td>\n      <td>7233</td>\n      <td>Nasi Dori Asam Manis</td>\n      <td>PAYMENT EXPIRED</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# import data and convert to df\n",
    "path = os.path.join(os.getcwd(), '../data/u.purchase.csv')\n",
    "\n",
    "names = ['user_id','username','item_id','product_name','status']\n",
    "df = pd.read_csv(path, ',', names=names, engine='python', skiprows=1) # skip header row\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove first x rows (only during development)\n",
    "df = df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     user_id  item_id\n",
       "3         12     6845\n",
       "9         12     6271\n",
       "12        76     7120\n",
       "13        76     7121\n",
       "14        76     7122\n",
       "..       ...      ...\n",
       "995     5627    12303\n",
       "996     5627     7940\n",
       "997     5627     7500\n",
       "998     5627     8548\n",
       "999     5627     7497\n",
       "\n",
       "[731 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>12</td>\n      <td>6845</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>12</td>\n      <td>6271</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>76</td>\n      <td>7120</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>76</td>\n      <td>7121</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>76</td>\n      <td>7122</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>5627</td>\n      <td>12303</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>5627</td>\n      <td>7940</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>5627</td>\n      <td>7500</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>5627</td>\n      <td>8548</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>5627</td>\n      <td>7497</td>\n    </tr>\n  </tbody>\n</table>\n<p>731 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# remove unused columns\n",
    "df.drop(['username', 'product_name'], axis=1, inplace=True)\n",
    "\n",
    "# only keep SUCCESS status\n",
    "df = df.drop(df[df.status!='SUCCESS'].index)\n",
    "df.drop(['status'], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[  0.,   1.,   1.],\n",
       "       [  0.,   0.,   1.],\n",
       "       [  1.,   2.,   1.],\n",
       "       ...,\n",
       "       [ 58., 453.,   1.],\n",
       "       [ 58., 454.,   1.],\n",
       "       [ 58., 455.,   1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# create array of shape [u-1, i-1] for user and item interactions\n",
    "users = np.array(df.user_id.unique())\n",
    "items = np.array(df.item_id.unique())\n",
    "n_users = len(users)\n",
    "n_items = len(items)\n",
    "\"\"\"\n",
    "Z = np.zeros((n_users, n_items))\n",
    "\n",
    "for user_i, u in enumerate(users):\n",
    "    # find all user's item interaction \n",
    "    u_i = df[df['user_id'] == u]\n",
    "    for _, i in u_i.iterrows():\n",
    "        # find index of item\n",
    "        item_i = np.where(items==i['item_id'])\n",
    "        Z[user_i, item_i] += 1\n",
    "\"\"\"\n",
    "\n",
    "R = np.array([[0,0,0]])\n",
    "\n",
    "\n",
    "for u in users:\n",
    "    # find list of item interactions\n",
    "    user_purchases = df[df['user_id']==u]['item_id']\n",
    "    unique, counts = np.unique(user_purchases, return_counts=True)\n",
    "    user_total_purchases = np.array(list(zip(unique, np.ones(counts.shape))))\n",
    "    user_total_purchases = np.insert(user_total_purchases, 0, [[u]], axis=1)\n",
    "\n",
    "    R = np.concatenate((R, user_total_purchases))\n",
    "\n",
    "R = np.delete(R, 0, 0)\n",
    "\n",
    "\n",
    "for i, interaction in enumerate(R):\n",
    "    # index user\n",
    "    user_id = interaction[0]\n",
    "    user_i = np.where(users==user_id)[0]\n",
    "    R[i][0] = user_i # replace id with index\n",
    "\n",
    "    # index item\n",
    "    item_id = interaction[1]\n",
    "    item_i = np.where(items==item_id)[0]\n",
    "    R[i][1] = item_i\n",
    "\n",
    "\n",
    "# delete first row\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(63, 3)\n(569, 3)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "TEST_SPLIT_RATIO = 0.1\n",
    "test_set_size = round(len(R) * TEST_SPLIT_RATIO)\n",
    "test_set_idx = np.random.choice(range(len(R)),\n",
    "                                size=test_set_size, replace=False)\n",
    "\n",
    "ts = R[test_set_idx]\n",
    "tr = np.delete(R, test_set_idx, axis=0)\n",
    "print(ts.shape)\n",
    "print(tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1. 1. 0. ... 0. 0. 0.]\n [0. 0. 1. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 1. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# create coo_matrix\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "u_tr, i_tr, r_tr = zip(*R)\n",
    "tr_sparse = coo_matrix((r_tr, (u_tr, i_tr)), shape=(n_users, n_items))\n",
    "\n",
    "print(tr_sparse.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(59, 458)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# make weights\n",
    "feature_wt_exp = 0.08\n",
    "\n",
    "frac = np.array(1.0/(tr_sparse > 0.0).sum(0))\n",
    "col_wts = np.array(np.power(frac, feature_wt_exp)).flatten()\n",
    "np.array(1/(tr_sparse > 0.0).sum(0))\n",
    "tr_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.factorization.python.ops import factorization_ops\n",
    "\n",
    "DEFAULT_PARAMS = {\n",
    "    'weights': True,\n",
    "    'latent_factors': 5,\n",
    "    'num_iters': 20,\n",
    "    'regularization': 0.07,\n",
    "    'unobs_weight': 0.01,\n",
    "    'wt_type': 0,\n",
    "    'feature_wt_factor': 130.0,\n",
    "    'feature_wt_exp': 0.08,\n",
    "    'delimiter': '\\t'\n",
    "}\n",
    "\n",
    "dim = DEFAULT_PARAMS['latent_factors']\n",
    "num_iters = DEFAULT_PARAMS['num_iters']\n",
    "reg = DEFAULT_PARAMS['regularization']\n",
    "unobs = DEFAULT_PARAMS['unobs_weight']\n",
    "wt_type = DEFAULT_PARAMS['wt_type']\n",
    "feature_wt_exp = DEFAULT_PARAMS['feature_wt_exp']\n",
    "obs_wt = DEFAULT_PARAMS['feature_wt_factor']\n",
    "\n",
    "row_wts = None\n",
    "\n",
    "\n",
    "num_rows = tr_sparse.shape[0]\n",
    "num_cols = tr_sparse.shape[1]\n",
    "\n",
    "row_wts = np.ones(num_rows)\n",
    "\n",
    "row_factor = None\n",
    "col_factor = None\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "    input_tensor = tf.SparseTensor(indices=list(zip(tr_sparse.row, tr_sparse.col)),\n",
    "                                   values=(tr_sparse.data).astype(np.float32),\n",
    "                                   dense_shape=tr_sparse.shape)\n",
    "\n",
    "    model = factorization_ops.WALSModel(num_rows, num_cols, dim,\n",
    "                                        unobserved_weight=unobs,\n",
    "                                        regularization=reg,\n",
    "                                        row_weights=row_wts,\n",
    "                                        col_weights=col_wts)\n",
    "\n",
    "    # retrieve the row and column factors\n",
    "    row_factor = model.row_factors[0]\n",
    "    col_factor = model.col_factors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "sess = tf.Session(graph=input_tensor.graph)\n",
    "\n",
    "with input_tensor.graph.as_default():\n",
    "    row_update_op = model.update_row_factors(sp_input=input_tensor)[1]\n",
    "    col_update_op = model.update_col_factors(sp_input=input_tensor)[1]\n",
    "\n",
    "    sess.run(model.initialize_op)\n",
    "    sess.run(model.worker_init)\n",
    "    for _ in range(num_iters):\n",
    "        sess.run(model.row_update_prep_gramian_op)\n",
    "        sess.run(model.initialize_row_update_op)\n",
    "        sess.run(row_update_op)\n",
    "        sess.run(model.col_update_prep_gramian_op)\n",
    "        sess.run(model.initialize_col_update_op)\n",
    "        sess.run(col_update_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.7633808 ,  0.23418975, -0.04187143, ...,  0.0861668 ,\n",
       "         0.9970003 ,  0.16619682],\n",
       "       [ 0.75673723,  0.24433696, -0.02583635, ...,  0.1043287 ,\n",
       "         1.0069507 ,  0.17695534],\n",
       "       [ 0.2216481 ,  0.89184934,  0.762364  , ..., -0.41047096,\n",
       "        -0.09587336, -0.253871  ],\n",
       "       ...,\n",
       "       [ 0.05078867, -0.071395  , -0.15302618, ...,  0.4054911 ,\n",
       "         0.34305036,  0.9346351 ],\n",
       "       [ 0.05078867, -0.071395  , -0.15302618, ...,  0.4054911 ,\n",
       "         0.34305036,  0.9346351 ],\n",
       "       [ 0.05078867, -0.071395  , -0.15302618, ...,  0.4054911 ,\n",
       "         0.34305036,  0.9346351 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# get prediction model\n",
    "\n",
    "# evaluate output factor matrices\n",
    "output_row = row_factor.eval(session=sess)\n",
    "output_col = col_factor.eval(session=sess)\n",
    "\n",
    "pred = np.dot(output_col, output_row.T)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(458, 59)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(63, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "print(pred.shape)\n",
    "ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(59, 458)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "27022"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# convert ts to weighted matrix\n",
    "u_ts = ts[:,0]\n",
    "i_ts = ts[:,1]\n",
    "r_ts = ts[:, 2]\n",
    "ts_sparse = coo_matrix((r_ts, (u_ts, i_ts)), shape=(n_users, n_items)).toarray()\n",
    "\n",
    "W = np.outer(row_wts, col_wts) + unobs\n",
    "ts_sparse *= W\n",
    "ts_sparse[ts_sparse==0] = unobs\n",
    "ts_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_from_indexes(a1, indexes):\n",
    "    a2 = np.array([])\n",
    "    for i in indexes:\n",
    "        a2 = np.append(a1[i[0]][i[1]], a2)\n",
    "    return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[  1   5]\n [  3  14]\n [  3  15]\n [  3  17]\n [  5  36]\n [  5  52]\n [  8  67]\n [  8  68]\n [  8  70]\n [ 10  76]\n [ 12  83]\n [ 14  97]\n [ 16 105]\n [ 16 110]\n [ 19 128]\n [ 21 131]\n [ 22 135]\n [ 23 142]\n [ 23 143]\n [ 26 156]\n [ 27 105]\n [ 27 108]\n [ 27 158]\n [ 27 159]\n [ 27 163]\n [ 28  90]\n [ 30 122]\n [ 30 203]\n [ 30 205]\n [ 30 225]\n [ 30 226]\n [ 31   6]\n [ 31 240]\n [ 33 126]\n [ 39 284]\n [ 40   6]\n [ 40 288]\n [ 41  82]\n [ 41 298]\n [ 41 300]\n [ 41 305]\n [ 44 109]\n [ 44 177]\n [ 45 316]\n [ 50 335]\n [ 50 337]\n [ 50 342]\n [ 50 354]\n [ 51   6]\n [ 51 376]\n [ 51 381]\n [ 51 391]\n [ 51 395]\n [ 52 397]\n [ 52 398]\n [ 52 403]\n [ 52 408]\n [ 57 341]\n [ 57 433]\n [ 58 250]\n [ 58 289]\n [ 58 435]\n [ 58 455]]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 3",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-1a62b8b32b97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnonzero_indexes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mts_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mpred_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmse\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred_value\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mts_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "import math\n",
    "nonzero_row, nonzero_col = np.nonzero(ts_sparse)\n",
    "nonzero_indexes = np.array((nonzero_row, nonzero_col)).T # gets list of indexes\n",
    "print(nonzero_indexes)\n",
    "# compare ts and prediction values\n",
    "mse = 0\n",
    "for i in nonzero_indexes:\n",
    "    ts_value = ts[i[0]][i[1]]\n",
    "    pred_value = pred[i[0]][i[1]]\n",
    "    mse += (pred_value - ts_value)**2\n",
    "    print(ts_value)\n",
    "    print(pred_value)\n",
    "mse /= len(nonzero_indexes)\n",
    "rmse = math.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}